{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b1e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import randint, uniform\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd32793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c461b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding da coluna 'category_code'\n",
    "category_dummies_train = pd.get_dummies(train['category_code'], prefix='category')\n",
    "category_dummies_test = pd.get_dummies(test['category_code'], prefix='category')\n",
    "\n",
    "# Alinhar colunas entre treino e teste\n",
    "category_dummies_test = category_dummies_test.reindex(columns=category_dummies_train.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa7ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar dummies ao dataset\n",
    "train = pd.concat([train, category_dummies_train], axis=1)\n",
    "test = pd.concat([test, category_dummies_test], axis=1)\n",
    "\n",
    "# Remover a coluna original 'category_code'\n",
    "train = train.drop(columns=['category_code'])\n",
    "test = test.drop(columns=['category_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be47af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas com valores faltantes para imputação\n",
    "cols_with_nan = [\n",
    "    'age_first_funding_year', 'age_last_funding_year',\n",
    "    'age_first_milestone_year', 'age_last_milestone_year',\n",
    "    'funding_total_usd'\n",
    "]\n",
    "\n",
    "# Imputação por mediana\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "train[cols_with_nan] = imputer.fit_transform(train[cols_with_nan])\n",
    "test[cols_with_nan] = imputer.transform(test[cols_with_nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac7a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas numéricas para padronizar\n",
    "num_cols = [\n",
    "    'age_first_funding_year', 'age_last_funding_year', 'age_first_milestone_year',\n",
    "    'age_last_milestone_year', 'relationships', 'funding_rounds',\n",
    "    'funding_total_usd', 'milestones', 'avg_participants'\n",
    "]\n",
    "\n",
    "# Padronização\n",
    "scaler = StandardScaler()\n",
    "train[num_cols] = scaler.fit_transform(train[num_cols])\n",
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb12c394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selecionadas com base na importância\n",
    "selected_features = ['relationships', 'funding_total_usd', 'age_last_milestone_year', 'age_last_funding_year', \n",
    "                     'age_first_milestone_year', 'age_first_funding_year', 'milestones', 'avg_participants', \n",
    "                     'funding_rounds', 'is_otherstate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e926343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancear classes com oversampling\n",
    "classe_0 = train[train['labels'] == 0]\n",
    "classe_1 = train[train['labels'] == 1]\n",
    "\n",
    "if len(classe_0) > len(classe_1):\n",
    "    classe_1_over = resample(classe_1, replace=True, n_samples=len(classe_0), random_state=42)\n",
    "    train_balanced = pd.concat([classe_0, classe_1_over])\n",
    "else:\n",
    "    classe_0_over = resample(classe_0, replace=True, n_samples=len(classe_1), random_state=42)\n",
    "    train_balanced = pd.concat([classe_0_over, classe_1])\n",
    "\n",
    "X_train = train_balanced[selected_features]\n",
    "y_train = train_balanced['labels']\n",
    "X_test = test[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b521d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelos\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf_model), ('gb', gb_model)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62915c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar ensemble com dados balanceados\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Prever no conjunto de teste\n",
    "predictions = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2661117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de submissão criado com sucesso: submission.csv\n"
     ]
    }
   ],
   "source": [
    "# Criar arquivo de submissão para Kaggle\n",
    "submission = sample_submission.copy()\n",
    "submission['labels'] = predictions\n",
    "submission.to_csv('submission_v5.csv', index=False)\n",
    "\n",
    "print('Arquivo de submissão criado com sucesso: submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
